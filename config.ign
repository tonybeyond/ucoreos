{
  "ignition": {
    "version": "3.5.0"
  },
  "passwd": {
    "users": [
      {
        "groups": [
          "wheel",
          "docker"
        ],
        "name": "core",
        "sshAuthorizedKeys": [
          "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIFZ3ItpfqjPT1XjQUX4uV/rnG7Lhm1NnG7WDzsU8FgJo machy@MiniMin.local"
        ]
      }
    ]
  },
  "storage": {
    "files": [
      {
        "path": "/etc/hostname",
        "contents": {
          "compression": "",
          "source": "data:,ucore-gpu-vm"
        },
        "mode": 420
      },
      {
        "path": "/etc/zincati/config.d/90-disable-auto-updates.toml",
        "contents": {
          "compression": "",
          "source": "data:,%5Bupdates%5D%0Aenabled%20%3D%20false%0A"
        },
        "mode": 420
      }
    ]
  },
  "systemd": {
    "units": [
      {
        "contents": "[Unit]\nDescription=Rebase to uCore and layer required packages\nWants=network-online.target\nAfter=network-online.target\n# This service should only run once on the very first boot.\nConditionPathExists=!/var/lib/setup-ucore.stamp\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\n# The 'rpm-ostree rebase' command can take '--install' arguments to layer\n# packages during the rebase. This is the correct, atomic way to do it.\n# This command will stage the new image and then reboot the system.\nExecStart=/usr/bin/rpm-ostree rebase ostree-unverified-registry:ghcr.io/ublue-os/ucore-minimal:stable \\\n  --install=qemu-guest-agent \\\n  --install=akmod-nvidia \\\n  --install=xorg-x11-drv-nvidia-cuda \\\n  --install=nvidia-container-toolkit\n# The 'ExecStartPost' directive runs *after* the main command succeeds.\n# This is the correct way to create a stamp file for a one-shot service.\nExecStartPost=/usr/bin/touch /var/lib/setup-ucore.stamp\n\n[Install]\nWantedBy=multi-user.target\n",
        "enabled": true,
        "name": "setup-ucore.service"
      },
      {
        "enabled": true,
        "name": "qemu-guest-agent.service"
      },
      {
        "contents": "[Unit]\nDescription=Generate CDI spec for NVIDIA GPUs\n# It should run after the nvidia drivers are fully loaded and initialized.\n# The akmods service handles the kernel module building on boot.\nAfter=akmods.service\nWants=akmods.service\n\n[Service]\nType=oneshot\n# The nvidia-ctk tool is installed from the nvidia-container-toolkit package.\nExecStart=/usr/bin/nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml\n\n[Install]\nWantedBy=multi-user.target\n",
        "enabled": true,
        "name": "nvidia-cdi-generate.service"
      },
      {
        "contents": "[Unit]\nDescription=Ollama LLM Container with NVIDIA GPU\nWants=network-online.target nvidia-cdi-generate.service\nAfter=network-online.target nvidia-cdi-generate.service\n\n[Service]\nRestart=always\n# Use ExecStartPre to ensure the image is up-to-date before starting.\nExecStartPre=-/usr/bin/podman pull docker.io/ollama/ollama:latest\n# The '--device nvidia.com/gpu=all' syntax correctly uses the CDI spec.\nExecStart=/usr/bin/podman run --rm --name ollama \\\n  --security-opt=label=disable \\\n  --device nvidia.com/gpu=all \\\n  -p 127.0.0.1:11434:11434 \\\n  -v ollama-data:/root/.ollama \\\n  docker.io/ollama/ollama:latest\nExecStop=/usr/bin/podman stop ollama\n\n[Install]\nWantedBy=multi-user.target\n",
        "enabled": true,
        "name": "ollama-container.service"
      },
      {
        "contents": "[Unit]\nDescription=Tailscale container\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nRestart=always\nExecStartPre=-/usr/bin/podman pull docker.io/tailscale/tailscale:latest\nExecStart=/usr/bin/podman run --rm --name=tailscaled \\\n  -v /var/lib/tailscale:/var/lib/tailscale \\\n  -v /dev/net/tun:/dev/net/tun \\\n  --network=host \\\n  --cap-add=NET_ADMIN,NET_RAW \\\n  docker.io/tailscale/tailscale:latest\nExecStop=/usr/bin/podman stop tailscaled\n\n[Install]\nWantedBy=multi-user.target\n",
        "enabled": true,
        "name": "tailscale-container.service"
      }
    ]
  }
}
